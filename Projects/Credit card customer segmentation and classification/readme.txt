This project was a Kaggle challenge that I participated in and it aims at classifying customers according to their credit card information, providing a valuable tool for financial institutions, including banks, for customer segmentation. My role in this project was to use my data science skills to perform  three activities such as to cluster the data to identify customer segments; use the identified customer segments to label the provided data; and build and deploy a classification model that can be used to identify a customerâ€™s segment given an instance. 

The project was executed using Python within a Jupyter notebook environment, encompassing tasks such as data preparation, exploratory data analysis, data pre-processing, unsupervised model creation and evaluation, hyperparameter tuning, and supervised model development. The final benchmark model was deployed using the Flask web framework, facilitating the identification of a new customer's segment.

 The exploratory data analysis (EDA) of the credit card dataset involved a thorough examination of its structure and columns, offering a comprehensive overview of its content. Statistical summaries were employed to highlight numerical columns, and non-contributory columns were identified for removal. The investigation extended to the analysis of data types, relationships between variables, outliers in each column, and the presence of missing values. 

In the development of unsupervised models, the optimal number of clusters was identified using silhouette scores for K-Means. Post-application of K-Means to scaled data, outliers were excluded, and data labeling by clusters ensued. The resultant labeled dataset was stored in a CSV file, ensuring a concise and accessible format for subsequent analysis.

The supervised machine learning phase involved the utilization of various models, including logistic regression, decision trees, support vector machines, and random forests. Cross-validation was performed using the 'cross_val_score' function from the scikit-learn library, employing 10 folds to prevent overfitting and provide a robust assessment of the model's generalization performance. 

Findings from the project indicated the presence of outliers in most columns and approximately 4% missing values. Mitigation measures included filling missing values with their average and handling outliers using the interquartile range method. Silhouette scores revealed that the optimal number of clusters was 3 due to its compact and distinct nature. Furthermore, through observation of the cross-validation score and learning curve, it was evident that the Support Vector Machine model exhibited superior performance with an accuracy of almost 99% compared to other models.

